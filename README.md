# Correr el api junto con la db

## en la carpeta principal esta el docker compose que levanta todo el proyecto

docker-compose up -d

la documentaci√≥n cuando sube el proyecto esta el ``localhost:8000/docs``

## para poder correr el proyecto de scrapy

* se instalan las librerias con del requirements
* y se corre dentro de la carpera procesos ``scrapy crawl getProcesos``
* el explorador el  firefox 113
